{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div align='center'>\n",
    "<font size=\"+2\">\n",
    "\n",
    "Text Mining and Natural Language Processing  \n",
    "2023-2024\n",
    "\n",
    "<b>SelectWise</b>\n",
    "\n",
    "Alessandro Ghiotto 513944\n",
    "\n",
    "</font>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 5 - Evaluation on the Test Set:\n",
    "\n",
    "Here I look at the performances on the test dataset of the two best methods.\n",
    "\n",
    "- BERT - combined method\n",
    "- DeciLM - few-shot prompting\n",
    "\n",
    "--- \n",
    "\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '3E7TUJ2EGCLQNOV1WEAJ2NN9ROPD9K',\n",
       " 'question': 'What type of water formation is formed by clouds?',\n",
       " 'choices': ['pearls',\n",
       "  'streams',\n",
       "  'shells',\n",
       "  'diamonds',\n",
       "  'rain',\n",
       "  'beads',\n",
       "  'cooled',\n",
       "  'liquid'],\n",
       " 'answerKey': 'F',\n",
       " 'fact1': 'beads of water are formed by water vapor condensing',\n",
       " 'fact2': 'Clouds are made of water vapor.',\n",
       " 'combinedfact': 'Beads of water can be formed by clouds.',\n",
       " 'formatted_question': 'What type of water formation is formed by clouds? (A) pearls (B) streams (C) shells (D) diamonds (E) rain (F) beads (G) cooled (H) liquid',\n",
       " 'answerKey_int': 5}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "\n",
    "# SEED\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.random.manual_seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "seed = 8\n",
    "set_seed(seed)\n",
    "\n",
    "# DEVICE and DTYPE\n",
    "mydevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.set_default_device(mydevice) # default tensor device\n",
    "# torch.set_default_dtype(torch.float32) # default tensor dtype\n",
    "\n",
    "# DATASET\n",
    "dataset = load_dataset(\"allenai/qasc\")\n",
    "n_train_sample = 7323\n",
    "dataset_train = dataset['train'].select(range(n_train_sample))\n",
    "dataset_val = dataset['train'].select(range(n_train_sample, len(dataset['train'])))\n",
    "dataset_test = dataset['validation']\n",
    "\n",
    "def format_choices(example):\n",
    "    if example['choices']['label'] == ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']:\n",
    "        example['choices'] = example['choices']['text']\n",
    "    else:\n",
    "        print(\"The order of the choices is not the same for all the examples\")\n",
    "    example['answerKey_int'] = ord(example['answerKey']) - 65\n",
    "    return example\n",
    "\n",
    "dataset_train = dataset_train.map(format_choices)\n",
    "dataset_val = dataset_val.map(format_choices)\n",
    "dataset_test = dataset_test.map(format_choices)\n",
    "\n",
    "# Display the dataset\n",
    "dataset_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **DeciLM**\n",
    "\n",
    "`'DeciLM-7B-instruct'`, with few shot prompting. Accuracy on validation dataset = 0.97411."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd3042fc20b42768d2648f75477d3be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
    "\n",
    "model_name = \"Deci/DeciLM-7B-instruct\"\n",
    "\n",
    "device = \"cuda\" \n",
    "\n",
    "dtype_kwargs = dict(\n",
    "    quantization_config=BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    "))\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    **dtype_kwargs\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    temperature=0.1,\n",
    "    top_p=0.9,\n",
    "    do_sample=True,\n",
    "    device_map=\"auto\",\n",
    "    max_new_tokens=256,\n",
    "    return_full_text=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(user_prompt, pipeline=pipe):\n",
    "    system_prompt = \"You are an AI assistant that follows instruction extremely well. Help as much as you can.\"\n",
    "    prompt = pipeline.tokenizer.apply_chat_template([\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ], tokenize=False, add_generation_prompt=True)\n",
    "    return pipeline(prompt)[0]['generated_text']\n",
    "\n",
    "import timeit\n",
    "\n",
    "def evaluate_model(dataset, question_format, pipeline=pipe):\n",
    "  total = 0\n",
    "  correct = 0\n",
    "  skipped = 0\n",
    "  wrong_aswers = []\n",
    "  t0 = timeit.default_timer()\n",
    "  # cicle over all the reviews\n",
    "  for i, item in enumerate(dataset):\n",
    "    true_label = item[\"answerKey\"]\n",
    "    prompt = question_format(item)\n",
    "    answer = get_response(prompt, pipeline)\n",
    "    output_label = answer.upper().replace(\"\\n\", \" \").strip()[0]\n",
    "    # output_label = output_label.replace(\"ANSWER:\", \"\").strip()[0]\n",
    "\n",
    "    # if the answer is not in the choices, we skip\n",
    "    if output_label not in ['A','B','C','D','E','F','G','H']:\n",
    "      print(answer)\n",
    "      skipped+=1 # counter of skipped sentences\n",
    "      continue # we simply continue the loop\n",
    "\n",
    "    if output_label == true_label: # CORRECT\n",
    "      correct+=1\n",
    "    else: # WRONG\n",
    "      wrong_aswers.append((i, output_label))\n",
    "    total+=1\n",
    "\n",
    "  delta_t = timeit.default_timer()-t0\n",
    "  print(f\"elapsed : {delta_t:.2f} seconds\")\n",
    "  print(f\"elapsed/iter : {delta_t/len(dataset):.5f} seconds\")\n",
    "  print(f\"skipped : {skipped}\")\n",
    "  print(f\"correct : {correct}\")\n",
    "  print(f\"accuracy: {correct/total:.5f}\")\n",
    "  return wrong_aswers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/.pyenv/versions/3.12.3/lib/python3.12/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
      "  self.gen = func(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed : 206.88 seconds\n",
      "elapsed/iter : 0.22341 seconds\n",
      "skipped : 0\n",
      "correct : 917\n",
      "accuracy: 0.99028\n"
     ]
    }
   ],
   "source": [
    "# dataset_train[0] as context\n",
    "\n",
    "def question_format(item):\n",
    "    question_formatted = f\"\"\"\\\n",
    "    fact1: beads of water are formed by water vapor condensing\n",
    "    fact2: Clouds are made of water vapor.\n",
    "    Question: What type of water formation is formed by clouds?\n",
    "    A) pearls\n",
    "    B) streams\n",
    "    C) shells\n",
    "    D) diamonds\n",
    "    E) rain\n",
    "    F) beads\n",
    "    G) cooled\n",
    "    H) liquid\n",
    "    Answer: F\n",
    "\n",
    "    fact1: {item['fact1']}\n",
    "    fact2: {item['fact2']}\n",
    "    Question: {item['question']}\n",
    "    A) {item['choices'][0]}\n",
    "    B) {item['choices'][1]}\n",
    "    C) {item['choices'][2]}\n",
    "    D) {item['choices'][3]}\n",
    "    E) {item['choices'][4]}\n",
    "    F) {item['choices'][5]}\n",
    "    G) {item['choices'][6]}\n",
    "    H) {item['choices'][7]}\n",
    "    Answer:\"\"\"\n",
    "    return question_formatted\n",
    "\n",
    "wrong_answers = evaluate_model(dataset_test, question_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDEX: 35\n",
      "    fact1: All cnidarians are aquatic.\n",
      "    fact2: Cnidarians include jellyfish and anemones.\n",
      "    Question: What kind of animal are jellyfish?\n",
      "    A) protozoa\n",
      "    B) adult\n",
      "    C) paramecium\n",
      "    D) dry\n",
      "    E) land-based\n",
      "    F) Porifera\n",
      "    G) anemones\n",
      "    H) aquatic\n",
      "    Answer: H\n",
      "OUTPUT LABEL: G\n",
      "\n",
      "\n",
      "\n",
      "INDEX: 103\n",
      "    fact1: when a gas in an open container evaporates , that gas spreads out into the air\n",
      "    fact2: Deadly carbon monoxide gas from the generator s exhaust can spread throughout enclosed spaces.\n",
      "    Question: carbon monoxide gas from a generator's exhaust has been what\n",
      "    A) transportation\n",
      "    B) air pollution\n",
      "    C) projectiles\n",
      "    D) destroyed crops\n",
      "    E) destruction\n",
      "    F) evaporated\n",
      "    G) danger\n",
      "    H) Car accidents\n",
      "    Answer: F\n",
      "OUTPUT LABEL: G\n",
      "\n",
      "\n",
      "\n",
      "INDEX: 104\n",
      "    fact1: Bone is less flexible than cartilage but stronger.\n",
      "    fact2: Sharks have a cartilage skeleton.\n",
      "    Question: What are less flexible than shark skeletons but stronger\n",
      "    A) holding nutrients\n",
      "    B) tissue paper\n",
      "    C) calibrated\n",
      "    D) plant stems\n",
      "    E) close relatives of coral\n",
      "    F) regular skeletons\n",
      "    G) clay\n",
      "    H) dermal & vascular tissue\n",
      "    Answer: F\n",
      "OUTPUT LABEL: D\n",
      "\n",
      "\n",
      "\n",
      "INDEX: 143\n",
      "    fact1: Lymph is a fluid that leaks out of capillaries into spaces between cells.\n",
      "    fact2: Bacteria invade lymph nodes, which swell, creating the buboes.\n",
      "    Question: What leak fluid out of capillaries into spaces between cells?\n",
      "    A) some anthozoans\n",
      "    B) swelling nodes\n",
      "    C) coelenterates\n",
      "    D) trucks and cars\n",
      "    E) black widows\n",
      "    F) unicellular organisms\n",
      "    G) Vibrissae\n",
      "    H) aquatic animals\n",
      "    Answer: B\n",
      "OUTPUT LABEL: A\n",
      "\n",
      "\n",
      "\n",
      "INDEX: 174\n",
      "    fact1: a seismometer is used to measure the strength or magnitude of an earthquake\n",
      "    fact2: Earthquakes are measured on a scale of 1 to 10.\n",
      "    Question: How do we grade earthquakes\n",
      "    A) Seisometers\n",
      "    B) Cladistics\n",
      "    C) feedback\n",
      "    D) Measuring the ground\n",
      "    E) Check out the sky\n",
      "    F) classified\n",
      "    G) Taking temperature\n",
      "    H) the Himalayas\n",
      "    Answer: A\n",
      "OUTPUT LABEL: F\n",
      "\n",
      "\n",
      "\n",
      "INDEX: 356\n",
      "    fact1: Sperm are deposited in the vagina during sexual intercourse.\n",
      "    fact2: Sexual union is for pleasure and closeness and for procreation.\n",
      "    Question: Sperm are deposited in the vagina during what?\n",
      "    A) procrastination\n",
      "    B) deviation\n",
      "    C) adolescence\n",
      "    D) amount of heat\n",
      "    E) minutes\n",
      "    F) coelenterates\n",
      "    G) union\n",
      "    H) procreation\n",
      "    Answer: H\n",
      "OUTPUT LABEL: G\n",
      "\n",
      "\n",
      "\n",
      "INDEX: 394\n",
      "    fact1: Mutualism is a symbiotic relationship in which both species benefit.\n",
      "    fact2: Domestication of animals is an example of a symbiotic relationship.\n",
      "    Question: Domestication of what is an example of Mutualism\n",
      "    A) minerals\n",
      "    B) farms\n",
      "    C) homes\n",
      "    D) lamphreys\n",
      "    E) trees\n",
      "    F) angiosperm\n",
      "    G) mammals\n",
      "    H) animals\n",
      "    Answer: H\n",
      "OUTPUT LABEL: G\n",
      "\n",
      "\n",
      "\n",
      "INDEX: 555\n",
      "    fact1: a watch is used for measuring time\n",
      "    fact2: Time management is the science of how to use the hours in a day more efficiently.\n",
      "    Question: What can a watch be used for?\n",
      "    A) safe operation\n",
      "    B) an infant's growth\n",
      "    C) hearing\n",
      "    D) water\n",
      "    E) help other species benefit\n",
      "    F) local weather conditions\n",
      "    G) studying weather\n",
      "    H) Scientific research\n",
      "    Answer: H\n",
      "OUTPUT LABEL: A\n",
      "\n",
      "\n",
      "\n",
      "INDEX: 565\n",
      "    fact1: Any surface that has not been sterilized is likely to be covered with bacteria.\n",
      "    fact2: Raw meat is loaded with harmful bacteria.\n",
      "    Question: What should you sterilize after placing an uncooked hamburger on it?\n",
      "    A) plasma and formed elements\n",
      "    B) Surfaces and counters\n",
      "    C) safe operation\n",
      "    D) Sesame Buns\n",
      "    E) antigens that cause allergy\n",
      "    F) Hot frying pans\n",
      "    G) Raw Meat\n",
      "    H) one-celled animals\n",
      "    Answer: B\n",
      "OUTPUT LABEL: G\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_item(item):\n",
    "    print(f\"\"\"\\\n",
    "    fact1: {item['fact1']}\n",
    "    fact2: {item['fact2']}\n",
    "    Question: {item['question']}\n",
    "    A) {item['choices'][0]}\n",
    "    B) {item['choices'][1]}\n",
    "    C) {item['choices'][2]}\n",
    "    D) {item['choices'][3]}\n",
    "    E) {item['choices'][4]}\n",
    "    F) {item['choices'][5]}\n",
    "    G) {item['choices'][6]}\n",
    "    H) {item['choices'][7]}\n",
    "    Answer: {item['answerKey']}\"\"\")\n",
    "\n",
    "for i, output_label in wrong_answers:\n",
    "    print(f\"INDEX: {i}\")\n",
    "    print_item(dataset_test[i])\n",
    "    print(f\"OUTPUT LABEL: {output_label}\")\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the sample 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDEX: 35\n",
      "    fact1: All cnidarians are aquatic.\n",
      "    fact2: Cnidarians include jellyfish and anemones.\n",
      "    Question: What kind of animal are jellyfish?\n",
      "    A) protozoa\n",
      "    B) adult\n",
      "    C) paramecium\n",
      "    D) dry\n",
      "    E) land-based\n",
      "    F) Porifera\n",
      "    G) anemones\n",
      "    H) aquatic\n",
      "    Answer: H\n",
      "OUTPUT LABEL: G\n"
     ]
    }
   ],
   "source": [
    "i = 35\n",
    "print(f\"INDEX: {i}\")\n",
    "print_item(dataset_test[i])\n",
    "print(f\"OUTPUT LABEL: {output_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I find interesting this example, because given the facts is a very simple question.\n",
    "\n",
    "fact1: cnidarians -> aquatic  \n",
    "fact2: jellyfish -> cnidarians  \n",
    "=> jellyfish -> aquatic\n",
    "\n",
    "But the model is kind of tricked by the presence of 'anemones' after the word jellyfish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fact1: All cnidarians are aquatic.\n",
      "    fact2: Cnidarians include anemones and jellyfish\n",
      "    Question: What kind of animal are jellyfish?\n",
      "    A) protozoa\n",
      "    B) adult\n",
      "    C) paramecium\n",
      "    D) dry\n",
      "    E) land-based\n",
      "    F) Porifera\n",
      "    G) anemones\n",
      "    H) aquatic\n",
      "    Answer: H\n",
      "OUTPUT LABEL:  H\n"
     ]
    }
   ],
   "source": [
    "example = dataset_test[i]\n",
    "example['fact2'] = 'Cnidarians include anemones and jellyfish'\n",
    "prompt = question_format(example)\n",
    "answer = get_response(prompt, pipe)\n",
    "print_item(example)\n",
    "print(f\"OUTPUT LABEL: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By changing the order of the words 'anemones' and 'jellyfish' I have got the correct answer. Maybe before we got the wrong answer because the sentence \"jellyfish are anemones\" is a very common pattern (NOUN to be NOUN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BERT**\n",
    "\n",
    "`'bert-base-uncased'`, first trained with linear probing (all weights freezen except the classifier head), than trained the rest of the architecture (all the weights active except the classifier head). Trained on the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMultipleChoice(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMultipleChoice\n",
    "\n",
    "mydevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "set_seed(seed)\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "\n",
    "# TOKENIZER\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "# MODEL\n",
    "model = AutoModelForMultipleChoice.from_pretrained(f\"../models/{model_name}-MultipleChoice-combinedmethod\")\n",
    "model.to(mydevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESS THE DATASET\n",
    "\n",
    "def preprocess_function_MultipleChoice(examples):\n",
    "    # attach fact1 and fact2\n",
    "    # and repeat each sentence 8 times to go with the 8 choices\n",
    "    first_sentences = [[f\"{examples[\"fact1\"][i]} {examples[\"fact2\"][i]}\"] * 8 for i in range(len(examples[\"fact1\"]))]\n",
    "    # Grab all second sentences, the questions.\n",
    "    questions = examples[\"question\"]\n",
    "    second_sentences = [\n",
    "        [f\"{question} [SEP] {examples[\"choices\"][i][choice_idx]}\" for choice_idx in range(8)] \n",
    "        for i, question in enumerate(questions)\n",
    "    ]\n",
    "\n",
    "    # Flatten everything\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "\n",
    "    # Tokenize\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "    # Un-flatten -> each example has 8 choices\n",
    "    tokenized_examples = {k: [v[i:i+8] for i in range(0, len(v), 8)] for k, v in tokenized_examples.items()}\n",
    "\n",
    "    # Create the labels\n",
    "    # ['A','B','C','D','E','F','G','H'] -> [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "    answerKeys = examples['answerKey'] \n",
    "    tokenized_examples['labels'] = [ord(answerKey) - ord('A') for answerKey in answerKeys]\n",
    "\n",
    "    return tokenized_examples\n",
    "\n",
    "# Apply the preprocessing function to the dataset\n",
    "dataset_test_encoded = dataset_test.map(preprocess_function_MultipleChoice, \n",
    "                                        batched=True, remove_columns=dataset_test.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "# CREATE THE DATACOLLATOR\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        # take the labels out\n",
    "        label_name = \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "\n",
    "        # flatten (because now I have a list of 8 choices for each example)\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [[{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "\n",
    "        # pad\n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # Un-flatten\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        # Add back labels\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# CREATE THE DATALOADER\n",
    "\n",
    "batch_size = 16\n",
    "generator = torch.Generator(device=mydevice)\n",
    "test_dataloader = DataLoader(dataset_test_encoded, batch_size=batch_size, shuffle=False,\n",
    "                            collate_fn=DataCollatorForMultipleChoice(tokenizer), generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed : 5.77 seconds\n",
      "elapsed/iter : 0.00623 seconds\n",
      "Test Accuracy:  0.97192\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import timeit\n",
    "\n",
    "# EVALUATE ON THE TEST SET\n",
    "\n",
    "model.eval()\n",
    "\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "incorrect_indices = []\n",
    "t0 = timeit.default_timer()\n",
    "for batch_idx, batch in enumerate(test_dataloader):\n",
    "    batch = {k: v.to(mydevice) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    accuracy_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "    # Identify incorrect predictions\n",
    "    incorrect_predictions = predictions != batch[\"labels\"]\n",
    "    \n",
    "    # Collect (idx, output_label) of incorrect predictions\n",
    "    if incorrect_predictions.any():\n",
    "        incorrect_indices.extend([(batch_idx * len(batch[\"labels\"]) + i, chr(predictions[i].item()+65))\n",
    "                                  for i, incorrect in enumerate(incorrect_predictions) if incorrect])\n",
    "        \n",
    "\n",
    "accuracy_result = accuracy_metric.compute()\n",
    "delta_t = timeit.default_timer()-t0\n",
    "print(f\"elapsed : {delta_t:.2f} seconds\")\n",
    "print(f\"elapsed/iter : {delta_t/len(dataset_test):.5f} seconds\")\n",
    "print(f\"Test Accuracy: {accuracy_result['accuracy']: .5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDEX: 11\n",
      "    fact1: a vehicle is used for transportation\n",
      "    fact2: Cars and busses are both examples of vehicles.\n",
      "    Question: What are busses used for?\n",
      "    A) Protective shelter\n",
      "    B) Transporting humans\n",
      "    C) help other species benefit\n",
      "    D) Transporting airplanes\n",
      "    E) A backbone\n",
      "    F) Communication\n",
      "    G) safe operation\n",
      "    H) safe driving\n",
      "    Answer: B\n",
      "OUTPUT LABEL: H\n",
      "\n",
      "\n",
      "INDEX: 35\n",
      "    fact1: All cnidarians are aquatic.\n",
      "    fact2: Cnidarians include jellyfish and anemones.\n",
      "    Question: What kind of animal are jellyfish?\n",
      "    A) protozoa\n",
      "    B) adult\n",
      "    C) paramecium\n",
      "    D) dry\n",
      "    E) land-based\n",
      "    F) Porifera\n",
      "    G) anemones\n",
      "    H) aquatic\n",
      "    Answer: H\n",
      "OUTPUT LABEL: G\n",
      "\n",
      "\n",
      "INDEX: 106\n",
      "    fact1: Bone is less flexible than cartilage but stronger.\n",
      "    fact2: Most fish have bony skeletons, but sharks have skeletons made of cartilage .\n",
      "    Question: What has a less flexible but stronger skeleton compared to sharks?\n",
      "    A) fish\n",
      "    B) Mohs\n",
      "    C) Type O\n",
      "    D) bacteria\n",
      "    E) cartilage\n",
      "    F) viruses\n",
      "    G) adult\n",
      "    H) weater\n",
      "    Answer: A\n",
      "OUTPUT LABEL: E\n",
      "\n",
      "\n",
      "INDEX: 114\n",
      "    fact1: bad weather decreases visibility while driving\n",
      "    fact2: Good visibility is essential for safe driving.\n",
      "    Question: Bad weather causes what sort of driving condition?\n",
      "    A) whiplash\n",
      "    B) death\n",
      "    C) danger\n",
      "    D) Unsafe\n",
      "    E) damaging\n",
      "    F) it depends\n",
      "    G) safe\n",
      "    H) no effect\n",
      "    Answer: D\n",
      "OUTPUT LABEL: G\n",
      "\n",
      "\n",
      "INDEX: 118\n",
      "    fact1: bad weather decreases visibility while driving\n",
      "    fact2: Collisions are more likely when visibility is poor.\n",
      "    Question: What conditions could make car accidents more likely?\n",
      "    A) Experienced drivers\n",
      "    B) the Arctic\n",
      "    C) Less traffic than usual\n",
      "    D) 5 mph winds\n",
      "    E) Thunderstorms\n",
      "    F) clog airways\n",
      "    G) trucks and cars\n",
      "    H) feedback mechanisms\n",
      "    Answer: E\n",
      "OUTPUT LABEL: C\n",
      "\n",
      "\n",
      "INDEX: 170\n",
      "    fact1: Growth is faster during infancy than it is during puberty.\n",
      "    fact2: Breasts develop during puberty .\n",
      "    Question: When is growth faster?\n",
      "    A) adulthood\n",
      "    B) sponges\n",
      "    C) when breasts develop\n",
      "    D) 86400\n",
      "    E) angiosperm\n",
      "    F) when menstruation stops\n",
      "    G) corn\n",
      "    H) infancy\n",
      "    Answer: H\n",
      "OUTPUT LABEL: C\n",
      "\n",
      "\n",
      "INDEX: 233\n",
      "    fact1: Nonmetal elements are far fewer in number.\n",
      "    fact2: Titanium is a lustrous white metallic element.\n",
      "    Question: What is titanium?\n",
      "    A) a metal\n",
      "    B) protection\n",
      "    C) solid\n",
      "    D) iron oxide\n",
      "    E) biological element\n",
      "    F) SI units\n",
      "    G) a non metal\n",
      "    H) cartilage\n",
      "    Answer: A\n",
      "OUTPUT LABEL: G\n",
      "\n",
      "\n",
      "INDEX: 324\n",
      "    fact1: Bile reduces the acidity of food entering from the highly acidic stomach.\n",
      "    fact2: Bile from the liver contains bile salts and many organic substances but no enzymes.\n",
      "    Question: what helps reduce acidity of food entering from the stomach?\n",
      "    A) cilia\n",
      "    B) fumes\n",
      "    C) kinase\n",
      "    D) liver\n",
      "    E) mucus\n",
      "    F) enzymes\n",
      "    G) insulin\n",
      "    H) herbs\n",
      "    Answer: D\n",
      "OUTPUT LABEL: F\n",
      "\n",
      "\n",
      "INDEX: 356\n",
      "    fact1: Sperm are deposited in the vagina during sexual intercourse.\n",
      "    fact2: Sexual union is for pleasure and closeness and for procreation.\n",
      "    Question: Sperm are deposited in the vagina during what?\n",
      "    A) procrastination\n",
      "    B) deviation\n",
      "    C) adolescence\n",
      "    D) amount of heat\n",
      "    E) minutes\n",
      "    F) coelenterates\n",
      "    G) union\n",
      "    H) procreation\n",
      "    Answer: H\n",
      "OUTPUT LABEL: G\n",
      "\n",
      "\n",
      "INDEX: 375\n",
      "    fact1: the type of material through which sound passes changes the speed at which sound travels\n",
      "    fact2: Sound Sound waves are mechanical waves.\n",
      "    Question: The type of material through which mechanical waves pass through changes what?\n",
      "    A) trucks and cars\n",
      "    B) melanin content\n",
      "    C) their color\n",
      "    D) their flavor\n",
      "    E) travel\n",
      "    F) amount of heat\n",
      "    G) their beams\n",
      "    H) their speed\n",
      "    Answer: H\n",
      "OUTPUT LABEL: E\n",
      "\n",
      "\n",
      "INDEX: 376\n",
      "    fact1: the type of material through which sound passes changes the speed at which sound travels\n",
      "    fact2: Sound vibrations travel at different speeds through different materials.\n",
      "    Question: what moves through different materials at different rates\n",
      "    A) silk\n",
      "    B) Speed\n",
      "    C) food\n",
      "    D) corn\n",
      "    E) weater\n",
      "    F) colors\n",
      "    G) sound\n",
      "    H) metal\n",
      "    Answer: G\n",
      "OUTPUT LABEL: B\n",
      "\n",
      "\n",
      "INDEX: 427\n",
      "    fact1: a speedometer is used for giving a driver feedback on the speed of their vehicle\n",
      "    fact2: Odometers and speedometers measure distance and speed.\n",
      "    Question: What does a speedometer measure?\n",
      "    A) Differences in speed\n",
      "    B) feedback mechanisms\n",
      "    C) Decimal fractions\n",
      "    D) transportation\n",
      "    E) How fast a vehicle is going\n",
      "    F) Driver's skill\n",
      "    G) Distance\n",
      "    H) How much gas a vehicle used\n",
      "    Answer: E\n",
      "OUTPUT LABEL: G\n",
      "\n",
      "\n",
      "INDEX: 433\n",
      "    fact1: a polar bear requires a cold environment\n",
      "    fact2: Polar bears have two layers of fur for further protection from the cold.\n",
      "    Question: Why do polar bears have two layers of fur?\n",
      "    A) 70-75 degrees Fahrenheit\n",
      "    B) Prevent injuries\n",
      "    C) To survive in their environment\n",
      "    D) Amount of melanin\n",
      "    E) To stay cold\n",
      "    F) Ultraviolet shielding\n",
      "    G) protective plates\n",
      "    H) To help them swim faster\n",
      "    Answer: C\n",
      "OUTPUT LABEL: E\n",
      "\n",
      "\n",
      "INDEX: 440\n",
      "    fact1: when a hurricane moves over land , that hurricane will decrease in strength\n",
      "    fact2: Hurricanes grow strength from warm waters.\n",
      "    Question: What makes a hurricane weaker?\n",
      "    A) Stronger winds\n",
      "    B) rapid changes occur\n",
      "    C) Tornadoes\n",
      "    D) Differences in speed\n",
      "    E) amount of heat\n",
      "    F) Being over land\n",
      "    G) chemical messengers\n",
      "    H) Warm water\n",
      "    Answer: F\n",
      "OUTPUT LABEL: H\n",
      "\n",
      "\n",
      "INDEX: 468\n",
      "    fact1: Precipitation increases moisture.\n",
      "    fact2: Rain is also known as precipitation.\n",
      "    Question: What can increase moisture?\n",
      "    A) small capillaries\n",
      "    B) wind blowing during a storm\n",
      "    C) trees and flowers\n",
      "    D) rapid changes occur\n",
      "    E) on a plant possessing stoma\n",
      "    F) some anthozoans\n",
      "    G) rain falling in the yard\n",
      "    H) eruption from a volcano\n",
      "    Answer: G\n",
      "OUTPUT LABEL: D\n",
      "\n",
      "\n",
      "INDEX: 488\n",
      "    fact1: a spider web is used to capture food by spiders\n",
      "    fact2: Larger numbers of spiders and spider webs means there are many insects available for food.\n",
      "    Question: What is used by spiders to capture insects?\n",
      "    A) flying\n",
      "    B) weapons\n",
      "    C) skin\n",
      "    D) Rolex\n",
      "    E) weater\n",
      "    F) electricity\n",
      "    G) food\n",
      "    H) webs\n",
      "    Answer: H\n",
      "OUTPUT LABEL: G\n",
      "\n",
      "\n",
      "INDEX: 506\n",
      "    fact1: Chromoplasts make and store pigments.\n",
      "    fact2: Chromoplasts are red, yellow or orange in hue due to the cartenoid pigments they contain.\n",
      "    Question: what are chromoplasts?\n",
      "    A) marine\n",
      "    B) cilia\n",
      "    C) Testes\n",
      "    D) orange\n",
      "    E) weater\n",
      "    F) hued\n",
      "    G) Type O\n",
      "    H) cells\n",
      "    Answer: F\n",
      "OUTPUT LABEL: D\n",
      "\n",
      "\n",
      "INDEX: 541\n",
      "    fact1: seconds are used to measure time\n",
      "    fact2: CPU time is measured in seconds.\n",
      "    Question: What computer component can you use to measure time?\n",
      "    A) size\n",
      "    B) wind\n",
      "    C) Mohs\n",
      "    D) Mouse\n",
      "    E) heat\n",
      "    F) CPU\n",
      "    G) Seconds\n",
      "    H) Hard drive\n",
      "    Answer: F\n",
      "OUTPUT LABEL: G\n",
      "\n",
      "\n",
      "INDEX: 561\n",
      "    fact1: Any surface that has not been sterilized is likely to be covered with bacteria.\n",
      "    fact2: Bacteria eat and bacteria digest foods.\n",
      "    Question: a surface that is not what is likely to be covered with something that eats and digests foods?\n",
      "    A) cartilage\n",
      "    B) plastic\n",
      "    C) dirty\n",
      "    D) sterilized\n",
      "    E) a hosta\n",
      "    F) covered in bacteria\n",
      "    G) Unsafe\n",
      "    H) tooth enamel\n",
      "    Answer: D\n",
      "OUTPUT LABEL: F\n",
      "\n",
      "\n",
      "INDEX: 565\n",
      "    fact1: Any surface that has not been sterilized is likely to be covered with bacteria.\n",
      "    fact2: Raw meat is loaded with harmful bacteria.\n",
      "    Question: What should you sterilize after placing an uncooked hamburger on it?\n",
      "    A) plasma and formed elements\n",
      "    B) Surfaces and counters\n",
      "    C) safe operation\n",
      "    D) Sesame Buns\n",
      "    E) antigens that cause allergy\n",
      "    F) Hot frying pans\n",
      "    G) Raw Meat\n",
      "    H) one-celled animals\n",
      "    Answer: B\n",
      "OUTPUT LABEL: G\n",
      "\n",
      "\n",
      "INDEX: 571\n",
      "    fact1: Any surface that has not been sterilized is likely to be covered with bacteria.\n",
      "    fact2: Potent liquid sterilant kills AIDS and other viruses on surfaces.\n",
      "    Question: What can sterilant be used for?\n",
      "    A) transportation\n",
      "    B) Warmer temperatures\n",
      "    C) trailers and boats\n",
      "    D) curing them\n",
      "    E) trees and flowers\n",
      "    F) Transporting humans\n",
      "    G) measuring device\n",
      "    H) clean a table\n",
      "    Answer: H\n",
      "OUTPUT LABEL: D\n",
      "\n",
      "\n",
      "INDEX: 662\n",
      "    fact1: seat belts are used for preventing injuries to passengers in cars\n",
      "    fact2: Seat Belts Seat belts provide primary protection in all types of crashes.\n",
      "    Question: What can car crashes do to passengers?\n",
      "    A) Injure them\n",
      "    B) Make them secure\n",
      "    C) clog airways\n",
      "    D) Unsafe\n",
      "    E) dehydration\n",
      "    F) Car accidents\n",
      "    G) Show them the way\n",
      "    H) Make cars better\n",
      "    Answer: A\n",
      "OUTPUT LABEL: F\n",
      "\n",
      "\n",
      "INDEX: 737\n",
      "    fact1: Food is easier to chew because it is moistened by saliva from the salivary glands.\n",
      "    fact2: Besides, saliva contains digestive enzymes .\n",
      "    Question: What do digestive enzymes make easier to chew?\n",
      "    A) water\n",
      "    B) food\n",
      "    C) 86400\n",
      "    D) sunlight\n",
      "    E) herbs\n",
      "    F) weater\n",
      "    G) saliva\n",
      "    H) fat\n",
      "    Answer: B\n",
      "OUTPUT LABEL: G\n",
      "\n",
      "\n",
      "INDEX: 780\n",
      "    fact1: a circle graph can be used to display percents\n",
      "    fact2: Circle Graphs A circle graph or pie graph uses a circle divided into sections to show data.\n",
      "    Question: what can be used to show data\n",
      "    A) earthquakes\n",
      "    B) differentiation\n",
      "    C) seasonal\n",
      "    D) artwork\n",
      "    E) percentages\n",
      "    F) windows\n",
      "    G) Cladistics\n",
      "    H) statues\n",
      "    Answer: E\n",
      "OUTPUT LABEL: B\n",
      "\n",
      "\n",
      "INDEX: 879\n",
      "    fact1: Sponges have specialized cells called collar cells.\n",
      "    fact2: Spicules, amoeboid cells, and collar cells are characteristic of sea anemones.\n",
      "    Question: What has a similar cell type to sponges?\n",
      "    A) some prokaryotes\n",
      "    B) sea anemone\n",
      "    C) shirt cells\n",
      "    D) some anthozoans\n",
      "    E) a hosta\n",
      "    F) coliform\n",
      "    G) coelenterates\n",
      "    H) collar cells\n",
      "    Answer: B\n",
      "OUTPUT LABEL: H\n",
      "\n",
      "\n",
      "INDEX: 804\n",
      "    fact1: a barometer is used to measure air pressure\n",
      "    fact2: Air pressure is a measure of the weight of the air.\n",
      "    Question: What does a barometer measure?\n",
      "    A) the air temperature\n",
      "    B) the weight of the air\n",
      "    C) the wind speed\n",
      "    D) Differences in speed\n",
      "    E) nutritious fluid\n",
      "    F) homeostasis\n",
      "    G) 295 degrees Kelvin\n",
      "    H) Warmer temperatures\n",
      "    Answer: B\n",
      "OUTPUT LABEL: F\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_item(item):\n",
    "    print(f\"\"\"\\\n",
    "    fact1: {item['fact1']}\n",
    "    fact2: {item['fact2']}\n",
    "    Question: {item['question']}\n",
    "    A) {item['choices'][0]}\n",
    "    B) {item['choices'][1]}\n",
    "    C) {item['choices'][2]}\n",
    "    D) {item['choices'][3]}\n",
    "    E) {item['choices'][4]}\n",
    "    F) {item['choices'][5]}\n",
    "    G) {item['choices'][6]}\n",
    "    H) {item['choices'][7]}\n",
    "    Answer: {item['answerKey']}\"\"\")\n",
    "\n",
    "for i, output_label in incorrect_indices:\n",
    "    print(f\"INDEX: {i}\")\n",
    "    print_item(dataset_test[i])\n",
    "    print(f\"OUTPUT LABEL: {output_label}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also BERT have done the same error that we have seen before with the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDEX: 35\n",
      "    fact1: All cnidarians are aquatic.\n",
      "    fact2: Cnidarians include jellyfish and anemones.\n",
      "    Question: What kind of animal are jellyfish?\n",
      "    A) protozoa\n",
      "    B) adult\n",
      "    C) paramecium\n",
      "    D) dry\n",
      "    E) land-based\n",
      "    F) Porifera\n",
      "    G) anemones\n",
      "    H) aquatic\n",
      "    Answer: H\n",
      "OUTPUT LABEL: G\n"
     ]
    }
   ],
   "source": [
    "i = 35\n",
    "for j, output_label in incorrect_indices:\n",
    "    if j == i:\n",
    "        output_label_i = output_label\n",
    "print(f\"INDEX: {i}\")\n",
    "print_item(dataset_test[i])\n",
    "print(f\"OUTPUT LABEL: {output_label_i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fact1: All cnidarians are aquatic.\n",
      "    fact2: Cnidarians include anemones and jellyfish\n",
      "    Question: What kind of animal are jellyfish?\n",
      "    A) protozoa\n",
      "    B) adult\n",
      "    C) paramecium\n",
      "    D) dry\n",
      "    E) land-based\n",
      "    F) Porifera\n",
      "    G) anemones\n",
      "    H) aquatic\n",
      "    Answer: H\n",
      "OUTPUT LABEL: G\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "example = dataset_test[i]\n",
    "example['fact2'] = 'Cnidarians include anemones and jellyfish'\n",
    "\n",
    "def pipeline_multiplechoice(example):\n",
    "    model.eval()\n",
    "\n",
    "    first_sentences = [f\"{example['fact1']} {example['fact2']}\"] * 8\n",
    "    second_sentences = [f\"{example['question']} [SEP] {example['choices'][choice_idx]}\" for choice_idx in range(8)] \n",
    "    # Tokenize\n",
    "    tokenized_example = tokenizer(first_sentences, second_sentences, truncation=True, \n",
    "                                   padding=True, return_tensors=\"pt\")\n",
    "\n",
    "    batch_size = 1\n",
    "    num_choices = 8\n",
    "    input = {k: v.view(batch_size, num_choices, -1).to('cuda') for k, v in tokenized_example.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**input)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    return chr(predictions[0].item() + 65)\n",
    "\n",
    "print_item(example)\n",
    "print(f\"OUTPUT LABEL: {pipeline_multiplechoice(example)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike DeciLM, the BERT model still does the same error, even if I have swapped 'anemones' and 'jellyfish'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fact1: All cnidarians are aquatic.\n",
      "    fact2: Cnidarians include jellyfish\n",
      "    Question: What kind of animal are jellyfish?\n",
      "    A) protozoa\n",
      "    B) adult\n",
      "    C) paramecium\n",
      "    D) dry\n",
      "    E) land-based\n",
      "    F) Porifera\n",
      "    G) anemones\n",
      "    H) aquatic\n",
      "    Answer: H\n",
      "OUTPUT LABEL: H\n"
     ]
    }
   ],
   "source": [
    "example = dataset_test[i]\n",
    "example['fact2'] = 'Cnidarians include jellyfish'\n",
    "\n",
    "print_item(example)\n",
    "print(f\"OUTPUT LABEL: {pipeline_multiplechoice(example)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we know that the erros is given by composing wrongly the facts. It's not given by some prior wrong information learned by the model during the pretraining. Because by removing the word 'anemones' the model classify correctly the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **Results**\n",
    "\n",
    "| Metric                         |bert-base-uncased           |DeciLM-7B-instruct    |\n",
    "|--------------------------------|:--------------------------:|:--------------------:|\n",
    "| Test Accuracy                  | $0.97192$                  | $\\bf{0.99028}$       |\n",
    "| Time Elapsed (seconds)         | $\\bf{5.77}$                | $208.88$             |\n",
    "| avg time elapsed for one sample| $\\bf{6.23 \\times 10^{-3}}$ | $2.23 \\times 10^{-1}$|\n",
    "\n",
    "The accuracy obtained with the LLM with few-shot promptig is a bit higher, but the time required is considerably higher. Instead BERT is incredibly fast.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
